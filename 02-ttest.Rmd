# One-sample and two-sample location tests

## One-sample and paired *t*-test 
We covered this example of Tech3Lab comparing the reaction time between individuals for two tasks, texting and speaking on the phone, while walking. The response variable is reaction time in seconds to the presence of a bicycle moving towards the participant.

The data can be found in `distraction.txt` and can be loaded in **R** in a `data.frame` object.

```{r distract_one-sample_t-test}
# get URL of the file
url <- "https://lbelzile.bitbucket.io/MATH60619A/distraction.txt"
# load data, stating header
data <- read.table(url, header = TRUE)
```

The columns of a `data.frame` object can be accessed using the `$` operator. 

We can calculate descriptive statistics for the data by using the commands `summary`, or `mean`, `sd`, etc.

Our goal is to compare the average reaction time for texting `t` and for call `c`, say $\mu_C=\mu_T$. Since the individuals complete the two assignments (the order is random), we are looking at a paired $t$-test, which amounts to comparing the null $\Hy_0: \mu_D=0$, where $\mu_D$ is the difference (in seconds) between the reaction time for texting vs phone conversation in the population. We can assess this graphically through an histogram of the distribution.

```{r hist_distract}
# create new vector as difference in time
D <- data$t - data$c
# histogram, on the probability scale
hist(D, probability = TRUE, 
     xlab = "Time difference between reaction time
         for texting and call (in seconds)",
     main = "")
# add density estimate
lines(density(D))
```

The two sample mean (standard error) are different, `r mean(data$t)` (`r  sd(data$t)`) seconds for texting and `r mean(data$c)` (`r  sd(data$c)`) seconds for call. To check if this is really the case, we perform a paired $t$-test.

```{r pairedttest}
ttest <- t.test(x = data$t, y = data$c, 
                alternative = "two.sided", paired = TRUE)
print(ttest)
```

The output provides the value of the test statistic $t = \overline{D}/\mathsf{se}(\overline{D})=$ `r ttest$statistic` with associated $p$-value `r print(ttest$p.value, digits= 4)`. We strongly reject the null hypothesis that $\mu_C=\mu_D$ at level 5% (even 1%), meaning that the reaction time is significantly longer on average for texting with an estimated 95% confidence of $[$ `r ttest$conf.int[1]`, `r ttest$conf.int[2]` $]$.

The null distribution of the test statistic is $\mathcal{T}_{34}$, so we can look at how extreme our test statistic is relative to a typical value from the null distribution.

```{r tdensity, echo = FALSE}
curve(expr = dt(x, df = ttest$parameter), 
      from = -4, to = 4, n = 1000L, yaxs = "i", ylim = c(0,0.45),
      xlab = "test-statistic", ylab = "density", bty = "l") 
abline(v = ttest$statistic, col = 2)
```

We can also do a one-sample $t$-test using the same function. The `hours` dataset consists of a sample of size $n=100$ of workers who had attained at least a college degree. We could test whether the participants work 40 hours a week (two sided alternative), or if they work more than that. In the latter case, the null hypothesis is thus $\Hy_0: \mu \geq 40$, where $\mu$ is the average number of weekly work hours, against the alternative $\Hy_1: \mu < 40$.


```{r hoursttest}
url <- "https://lbelzile.bitbucket.io/MATH60619A/hours.txt"
data <- read.table(file = url, header = TRUE)
ttest_twosided <- t.test(data, alternative = "two.sided", mu = 40)
ttest_onesided <- t.test(data, alternative = "greater", mu = 40)
```

In both cases, we reject the null hypothesis at level 5%, but the one-sided alternative has a smaller $p$-value. Think about why it does not make sense to test for $\Hy_0: \mu \leq 40$ versus $\Hy_1: \mu >40$ in view of the sample mean. 

## Two-sample *t*-test

We use the same example covered in slides for the `tickets` data. Since the research question is "Does paying by credit card encourage consumers to pay more?", this calls for a one sided test, with $\Hy_1: \mu_{\text{cred}} > \mu_{\text{cash}}$ and _de facto_ the null hypothesis must be $\Hy_0: \mu_{\text{cred}} \leq \mu_{\text{cash}}$. The alternative hypothesis is the one we _would_ be interested in checking, but because we are the Devil's advocate, the null hypothesis is the opposite and includes all other possibilities. Note that we only need to consider the case $\mu_{\text{cred}} = \mu_{\text{cash}}$ (why?), so one often write this as the null hypothesis.

We can start by loading the data and preliminary visual inspection. In light of the boxplot, it seems that the variance in the two groups differs.

```{r loadtickets}
url <- "https://lbelzile.bitbucket.io/MATH60619A/tickets.txt"
tickets <- read.table(url, header = TRUE) #load data
head(tickets) #print first six lines
boxplot(offer ~ group, data = tickets)
tickets$group <- factor(x = tickets$group, #cast binary to categ
                        labels = c("cash","credit")) #assign meaningful 
# summarize data by group (equivalent of PROC MEANS in SAS)
with(data = tickets, #use data
     expr = by(data = offer, FUN = summary, INDICES = group))
with(data = tickets, 
     expr = by(data = offer, FUN = sd, INDICES = group))
# alternatively
# sd(tickets$offer[tickets$group == "cash"])
```


The option `header = TRUE` specifies that the first line of the file contains the name of the variables. While `read.table` is the default for command to read tables (with options `sep` for the separator, we will also encounter `read.csv` for comma-separated values. The data is stored in a `data.frame` object. The command `str` gives a description of the observations (with the type) and `head` prints the first lines. Other relevant commands include `ndim`, `nrow` and `ncol` that give the dimensions of the data, the number of rows and the number of columns, respectively. 

Reference to the columns of a data frame is made using their column names (`colnames(tickets)`) using `$`, so `tickets$group` returns the second column with the binary variable. Alternatively, we can use the `attach` command to attach the dataset, in which case the variables are now accessible directly. Beware with this, as there is a risk of having multiple objects with the same name. A good practice is to `detach` the dataset after use.

When we load a dataset, the default option for strings is to cast them to factor (i.e., categorical variables). We do this likewise for the binary variables, even if in this case this makes no difference (but it is good practice).

Summary statistics showed that the mean amount offered for tickets is `r round(mean(tickets$offer[tickets$group == "cash"]),2)` (`r round(sd(tickets$offer[tickets$group == "cash"]), 1)`) for the group paying by cash and `r round(mean(tickets$offer[tickets$group == "credit"]),2)` (`r round(sd(tickets$offer[tickets$group == "credit"]), 1)`), but we need to perform a test in order to know whether such a difference, `r  round(mean(tickets$offer[tickets$group == "cash"])- mean(tickets$offer[tickets$group == "credit"]),2)`, is significative. Since our null hypothesis is that customers are willing to pay more by credit card, we perform a one-sided $t$-test.

```{r ttest_tickets}
ttest <- t.test(formula = offer ~ group, 
       data = tickets, 
       alternative = "less", #one-sided
       var.equal = TRUE) #by default FALSE
print(ttest)
```

In **R**, the default option for the function `t.test` is Welch's test (`var.equal = FALSE`), since the latter is valid whether or not the variance of the two groups are equal. The value of the test statistic is `r round(ttest$statistic,2)`, which should follow a Student $t$ distribution under $H_0$ with `r as.vector(ttest$ttest$parameter)` degrees of freedom, leading to a $p$-value smaller than $10 \times 10^{-3}$. We reject the null at level $\alpha=0.05$ in favor of the alternative that people paying by credit card are willing to spend more than those paying by cash with the lower bound of the 95\% confidence interval for this difference being `r round(ttest$conf.int[2], 2)`.

The equality test for the variance is not calculated directly by `t.test` in **R**, but the function `var.test` implements an $F$ test for this hypothesis (Levene's test is in `car::leveneTest`). We have overwhelming evidence that the variance for the two groups are unequal, so we can should Welch's test rather that the two-sample $t$-test. The conclusions are the same in this case, namely that such a difference is implausible if the true average were equal.

```{r ttest_unequalvar}
var.test(formula = offer ~ group, 
       data = tickets)
#Levene's test (same as SAS output)
car::leveneTest(offer ~ group, 
       data = tickets)
t.test(formula = offer ~ group, 
       data = tickets, 
       alternative = "less")
```

It now remains to check the normality assumption graphically; **SAS** prints histograms with superimposed densities and box-and-whiskers plots. We can also add quantile-quantile plots; the basic function is `qqnorm` in **R** and `qqline` adds a line passing through the first and third quartile, but we use the `qqPlot` function from the `car` package instead, since the latter includes a grid in the background and simulated approximate 95\% pointwise confidence intervals. The discreteness of the observations in the cash group is visible (corresponding to horizontal segments). Here, due to large enough sample sizes, we have no evidence against normality even if the variances are obviously different.

```{r plottickets}
par(mfrow = c(1,2), mar = c(4,4,1,1)) #change margins,
# mfrow = c(1,2) gives two plots side by side
boxplot(offer ~ group, data = tickets, 
        main = "Box-and-whiskers plot", 
        ylab = "Amount offered (in dollars)",
        frame = FALSE)

# Histogram 
# Attach dataset - variables (columns) are now visible
# avoids having tickets$group everywhere, now group
attach(tickets)
hist(x = offer[group == "cash"], 
     breaks = 10,
     xlim = range(offer),
     freq = FALSE, # density scale
     xlab = "Amount offered (in dollars)",
     main = "Histogram",
     col = rgb(1, 0, 0, 0.5))
#Add the second group to the plot
hist(x = offer[group == "credit"], 
     breaks = 10,
     add = TRUE,
     freq = FALSE,
     col = rgb(0, 0, 1, 0.5))
legend(x = "topright", 
       col = c("red", "blue"), 
       legend = c("cash", "credit"), 
       bty = "n",
       lwd = 5)
#superimpose density lines
lines(density(offer[group == "cash"]), 
      lty = 2,
      col = "red")
lines(density(offer[group == "credit"]), 
      lty = 2,
      col = "blue")
# Add normal density lines
lines(curve(dnorm(x,
            mean = mean(offer[group == "cash"]),
            sd = sd(offer[group == "cash"])), 
            from = 30, 
            to = 150,
            add = TRUE),
      col = "red")
lines(curve(dnorm(x,
            mean = mean(offer[group == "credit"]),
            sd = sd(offer[group == "credit"])), 
            from = 30, 
            to = 150,
            add = TRUE),
      col = "blue")

# Quantile-quantile plots
# install `car` package (only once)
# uncomment following line to install
# install.packages("car")
# default function is `qqnorm
car::qqPlot(offer[group == "cash"],
            ylab = "observed quantiles (cash)")
car::qqPlot(offer[group == "credit"],
            ylab = "observed quantiles (credit)")
# alternatively
# qqnorm(offer[group=="cash"], main = "cash")
# qqline(offer[group=="cash"])
# Detach dataset (don't forget)
detach(tickets)
```

## Wilcoxon rank sum test

If the data are not normal, either because the distribution is skewed or heavy-tailed, or because the sample sizes are small enough that the asymptotic distribution of the Welch test or the two-sample $t$-test is unreliable, we may resort to non-parametric procedures. The Wilcoxon rank-sum test is a test for a shift in distribution; the drawback is that it requires the distribution of the samples to be the same, up to a change in location. If the mean is finite, then this amounts to a change in mean under the assumption that $F_1(x-\Delta)=F_0(x)$ for any $x$ for $F_0, F_1$ the distribution function in group 0 and 1, respectively.


The syntax for the test is analogous to that of the other using the formula `y ~ x`, namely `wilcox.test(offer ~ groupe, data = tickets)`. You can also specify the values for the two samples with the arguments `x` and `y`.
The Wilcoxon rank sum test works with ranks, which is the relative position of the observations in the pooled sample. Intuitively, if there is no difference and both samples come from the same distribution $F_0(x)$, the sum of the ranks in either group (relative to the number of observations in that group) should not be systematically too large or too small. Because ranks are bounded by $n$, the test statistic is less sensitive to outliers or extremes, even if its power is not as great in small samples, the loss of power is often not meaningful and the robustness is appealing, which is why Wilcoxon rank sum test is widely used in practice. Since ranks are discrete, the distribution of the sum is tractable and we can use combinatorics to list all possibilities. For example, with eight observations split in two subgroups of equal size, the null distribution is 

```{r combina6choose3, echo = FALSE}
combo <- combn(8, 4)
nulldist <- table(colSums(combo))/ncol(combo)
test <- xtable::xtable(t(nulldist*100), 
                       caption = "Empirical distribution of rank sum", 
                       digits = 0)
rownames(test) <- "Probability (%)"
kableExtra::kable(test, digits = 1)
```

Note that the value returned by **R** for the Wilcoxon rank sum test is not the same as the formula covered in class; it subtracts the minimum possible rank sum, here  $m(m+1)/2$ for a first sample of size $m$ so that the statistic is bounded below by zero, regardless of the sample size. As this is a shift by a deterministic constant, it has no impact on the asymptotic distribution.

In practice, there will often be ties (when two values are identical) and this means that the ranks are not uniquely defined (we could assign ranks at random for ties, or take the average, etc.); **R** will print a warning message to notify the user of the presence of ties. Formulae are adapted to deal with ties, but the software computes these automatically for us. While you will see multiple online references to the function `wilcox.test`, it does not return the correct $p$-value, point estimate or confidence interval as soon as there are ties --- it is unfortunately is not doing the right thing. Outside of small samples, tabulating the null distribution is prohibitive if there are more than 50 observations in total, since the total number of possibilities explodes. In class, we saw that a normal approximation for the null distribution, i.e., the distribution of the rank sum test under the assumption that the two samples, of size $n_1$ and $n-n_1=n_2$, respectively, both have distribution function $F$. The distribution can easily be approximated by simulation, by sampling uniformly integer values from 1 to $n$ and summing the first $n_1$. We can repeat this a large number of times and get a good approximation. If there are ties, we proceed accordingly by resampling $n_1$ of the $n$ ranks, without replacement. The normal approximation, whose formula was given in the slides, matches quite closely the empirical distribution of the simulated values; this is a consequence of the central limit theorem. Because of the normal approximation, we can do two-sided tests exactly as before by defining exteme values as deviation from the mean either side.


We illustrate this concept with the `tickets` data; bear in mind that the test is not valid here, because the data clearly do not come from the same distribution up to a shift (in particular, the variance are clearly not the same). We would normally need to test formally for equality of distribution up to a location shift, but this requires yet another test; most of the time, we will assess this hypothesis graphically. 

```{r wilcoxsimu, cache = TRUE}
n <- nrow(tickets)
# correct p-value, wrong confint and pe
exactRankTests::wilcox.exact(offer ~ group, data = tickets, conf.int = TRUE)
# wrong p-value b/c of ties, correct confint and pe
wilcox.test(offer ~ group, data = tickets, conf.int = TRUE)
# Test statistic is sum of ranks
Wteststat <- sum(rank(tickets$offer, 
                      ties.method = "average")[tickets$group == "cash"])
         
# Compute the p-value through simulation
prank <- rank(tickets$offer, 
             ties.method = "average")
nrep <- 1e6L
W <- rep(0, nrep)
for(i in 1:nrep){
   #resample the ranks
   x <- sample(prank, size = 33, replace = FALSE)
   W[i] <- sum(x)
}
n1 <- 33; 
n2 <- 31

hist(W, freq = FALSE, 
     ylab = "density", 
     xlab = "simulated $W$", 
     main = "") #remove title
abline(v = Wteststat, col = "red")# add line for test stat

# Warning: this normal approximation is for
# data w/o ties, i.e., the formula presented
# in the course slides 
mues <- n1*(n1+n2+1)/2 #mean of normal approx
sdes <- sqrt(n1*n2*(n1+n2+1)/12) #var of normal approx
#superimpose normal approx to empirical distribution
lines(seq(700, 1600, length = 1000L),
dnorm(x <- seq(700, 1600, length = 1000L),
      mean = mues, sd = sdes), lwd = 2, col = 4)
# Simulated one-sided p-value
# by defn, proportion of samples as extreme (i.e. smaller)
mean(W < Wteststat)
#p-value from normal approx
pnorm(q = Wteststat, mean = mues, sd = sdes)
# One sided confidence interval based on normal approx.
mues-qnorm(0.95)*sdes
```

The value returned for the $p$-value by `wilcox.exact` would be roughly twice the one-sided $p$-value, in this case. The normal approximation is also convenient for obtaining confidence intervals, here [`r mues-qnorm(0.95)*sdes`, $\infty$). 

The `wilcox.test` function returns the so-called Hodges--Lehmann estimator (i.e., the median of all the pairs $Y^{(1)}_i-Y^{(2)}_j$ ($i=1, \ldots, n_1$; $j=1, \ldots, n_2$). These point estimators, the associated confidence intervals and the exact coverage of the intervals (with additionally the subtleties surrounging from ties and zeros) are beyond the scope of the course, but [Charles Geyer's course notes give additional information](http://www.stat.umn.edu/geyer/5601/examp/ranksum.html). The following function is adapted from his code and is distributed under [CC BY-SA 3.0](https://creativecommons.org/licenses/by-sa/3.0/) licence. It can be used to compute the Hodges--Lehmann estimator with the associated confidence interval, while also returning the coverage (not exactly 95% because of the discreteness of the data).

```{r hodgeslehmann} 
source("https://lbelzile.bitbucket.io/MATH60619A/hl_wilcox.R")
hl <- hl.wilcox(tickets$offer[tickets$group == "credit"], 
          tickets$offer[tickets$group == "cash"])
```

Another potential nonparametric test is the Fligner--Policello test. Unlike Wilcoxon rank sum, it does not assume that the two distributions are equal under the null hypothesis, but require them to be symmetrical around their median (so the variance  in each group could be different). [**SAS** implements the test and uses the asymptotic normal approximation for _p_ values and such like](http://support.sas.com/documentation/cdl/en/statug/67523/HTML/default/viewer.htm#statug_npar1way_details20.htm).

In **R**, the `NSM3` package provides an implementation of the Fligner--Policello test.

```{r fptest}
fptest <- NSM3::pFligPoli(tickets$offer[tickets$group == "credit"], 
          tickets$offer[tickets$group == "cash"])
1-fptest$p.val
```

The estimated $p$-value for the one-sided test is $0.0017$.